{
    "n_head": 32,
    "n_vocab": 50260,
    "embed_dropout": 0,
    "lr": 0.0002,
    "lr_decay": "cosine",
    "warmup_steps": 3000,
    "beta1": 0.9,
    "beta2": 0.9999,
    "epsilon": 1e-8,
    "ada_epsilon1": 1e-30,
    "ada_epsilon2": 1e-3,
    "opt_name": "adam",
    "weight_decay": 0.1,
    "train_batch_size": 256,
    "attn_dropout": 0,
    "train_steps": 572300,
    "eval_steps": 0,
    "predict_steps": 1,
    "res_dropout": 0,
    "eval_batch_size": 64,
    "predict_batch_size": 1,
    "iterations": 100,
    "n_embd": 2048,
    "datasets": [["openwebtext", 21, "documents_random", 1.0]],
    "model": "GPT",
    "model_path": "gs://train_gpt3_openwebtext_myresults/models/GPT3_XL",
    "n_ctx": 2048,
    "n_layer": 24,
    "scale_by_depth": true,
    "scale_by_in": false,
    "rezero" : true,
    "attention_types" :  [[["linear"],12],[["global"],12]],
    "moe_layers": [24],
    "moe_params": {
        "moe_dropout_rate": 0
    },
    "mesh_shape": "x:2,y:4",
    "layout": "batch:x,heads:y,vocab:y,intermediate_expanded:y,experts:y",
    "activation_function": "gelu",
    "recompute_grad": true,
    "gradient_clipping": 1.0,
    "tokens_per_mb_per_replica": 2048,
    "precision": "bfloat16"
}
